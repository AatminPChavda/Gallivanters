{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import keras\n",
    "import pickle\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from numpy import argmax\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating array ranging from 1 to 211\n",
    "CATEGORIES = []\n",
    "for i in range (1,212):\n",
    "    CATEGORIES.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"train\"\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR,category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the features\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y array to store input and output\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling of x and y with features and labels respectively\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "#reshaping of x    \n",
    "x = np.array(x).reshape(-1,IMG_SIZE,IMG_SIZE,3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle_out = open(\"x.pickle\",\"wb\")\n",
    "pickle.dump(x,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"x.pickle\",\"rb\")\n",
    "x = pickle.load(pickle_in)\n",
    "x = pickle.load(open(\"x.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing values between 0 to 1\n",
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shaping y to work on category(211)\n",
    "y = np_utils.to_categorical(y, 211)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "               kernel_size=(2,2), \n",
    "               strides=(1,1),\n",
    "               padding='same',\n",
    "               input_shape=x.shape[1:],\n",
    "               data_format='channels_last'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "\n",
    "\"\"\"model.add(Conv2D(filters=32,\n",
    "               kernel_size=(2,2),\n",
    "               strides=(1,1),\n",
    "               padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "\"\"\"\n",
    "model.add(Conv2D(filters=64,\n",
    "               kernel_size=(2,2),\n",
    "               strides=(1,1),\n",
    "               padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "\"\"\"\n",
    "model.add(Conv2D(filters=128,\n",
    "               kernel_size=(2,2),\n",
    "               strides=(1,1),\n",
    "               padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                     strides=2))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())        \n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(211))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 32)        416       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 64)        8256      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               10617344  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 211)               54227     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 211)               0         \n",
      "=================================================================\n",
      "Total params: 10,811,571\n",
      "Trainable params: 10,811,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5636 samples, validate on 1410 samples\n",
      "Epoch 1/10\n",
      "5636/5636 [==============================] - 43s 8ms/sample - loss: 5.1796 - categorical_accuracy: 0.0270 - val_loss: 4.8617 - val_categorical_accuracy: 0.0716\n",
      "Epoch 2/10\n",
      "5636/5636 [==============================] - 41s 7ms/sample - loss: 4.3053 - categorical_accuracy: 0.1482 - val_loss: 4.2619 - val_categorical_accuracy: 0.1461\n",
      "Epoch 3/10\n",
      "5636/5636 [==============================] - 41s 7ms/sample - loss: 3.1521 - categorical_accuracy: 0.3419 - val_loss: 2.9632 - val_categorical_accuracy: 0.4007\n",
      "Epoch 4/10\n",
      "5636/5636 [==============================] - 41s 7ms/sample - loss: 2.2470 - categorical_accuracy: 0.5098 - val_loss: 2.3438 - val_categorical_accuracy: 0.5113\n",
      "Epoch 5/10\n",
      "5636/5636 [==============================] - 41s 7ms/sample - loss: 1.5191 - categorical_accuracy: 0.6469 - val_loss: 2.5287 - val_categorical_accuracy: 0.5355\n",
      "Epoch 6/10\n",
      "5636/5636 [==============================] - 42s 8ms/sample - loss: 1.0706 - categorical_accuracy: 0.7433 - val_loss: 1.8398 - val_categorical_accuracy: 0.6404\n",
      "Epoch 7/10\n",
      "5636/5636 [==============================] - 42s 7ms/sample - loss: 0.7340 - categorical_accuracy: 0.8155 - val_loss: 2.2888 - val_categorical_accuracy: 0.5915\n",
      "Epoch 8/10\n",
      "5636/5636 [==============================] - 42s 8ms/sample - loss: 0.5122 - categorical_accuracy: 0.8683 - val_loss: 2.1001 - val_categorical_accuracy: 0.6589\n",
      "Epoch 9/10\n",
      "5636/5636 [==============================] - 43s 8ms/sample - loss: 0.3764 - categorical_accuracy: 0.9022 - val_loss: 2.2231 - val_categorical_accuracy: 0.6582\n",
      "Epoch 10/10\n",
      "5636/5636 [==============================] - 42s 8ms/sample - loss: 0.2977 - categorical_accuracy: 0.9244 - val_loss: 2.0742 - val_categorical_accuracy: 0.6809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b700f47dd8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\",optimizer = 'rmsprop' ,metrics = ['categorical_accuracy'])\n",
    "model.fit(x,y,batch_size = 32,epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading country labels\n",
    "with open(\"country.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary of country labels\n",
    "CAT = {}\n",
    "for i in range (1,212):\n",
    "    CAT[str(i-1)]=data[str(i)].split(',')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare test data compatible to feed into to model\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 75\n",
    "    img_array = cv2.imread(filepath)\n",
    "    new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "    return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Preparation of test data set to feed into model and store results in results\n",
    "path=\"test\"\n",
    "result=[]\n",
    "for img in range (1,1056):     #os.listdir(path):\n",
    "    #print (img)\n",
    "    prediction = model.predict(prepare(os.path.join(path,str(img)+\".jpg\")))\n",
    "    inverted = argmax(prediction[0])\n",
    "    result.append(CAT[str(inverted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting results to pandas dataframe to export it to json file\n",
    "Y_test=pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting result to csv file\n",
    "Y_test.index+=1\n",
    "Y_test.index\n",
    "export_csv = Y_test.to_csv ('./Ytest.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india\n"
     ]
    }
   ],
   "source": [
    "#Individual prediction\n",
    "prediction = model.predict([prepare('./test/700.jpg')])\n",
    "inverted = argmax(prediction[0])\n",
    "print(CAT[str(inverted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
